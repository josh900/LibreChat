<!-- Generated by SpecStory -->

# Fetch models for user-specific API keys (2025-09-10 03:12Z)

_**User (2025-09-10 03:12Z)**_

I have this issue with this librechat repo where when using my litellm server as a custom endpoint and adding it like this:
```
endpoints:
  custom:
    - name: "LiteLLM"
      apiKey: "user_provided"
      baseURL: "https://litellm.skoop.digital/v1"
      models:
        default: ["gemini/gemini-2.0-flash-lite","openai/gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "gemini/gemini-2.0-flash-lite"
      summarize: false
      summaryModel: "gemini/gemini-2.0-flash-lite"
      forcePrompt: false
      modelDisplayLabel: "LiteLLM"
```

It seems to only fetch models when setting the docker up or something, but I have differant api keys set on my litellm for each user of librechat. I need the users to be able to each use their own key. I need to fetch the  models available when the key is entered andmaybe when user logs in or refreshes the page, as litellm will always give the models for the api key specified. 

Serarch the repo and issue threads in repo (https://github.com/danny-avila/LibreChat) and docs (https://www.librechat.ai/docs/) for more info on how this can be done with the existing features. If we can't find anything in the existing features, we will need to modify this fork of the repo to be able to do this. If we need tomodify the repo it needs to be in one post-install script that automatically makes the changes to the docker after running it each  time it's built, but ideally we would do it without mofifying the deployment.

---

_**Assistant**_

<think><details><summary>Thought Process</summary>The user is having an issue with LibreChat where they want to use their LiteLLM server as a custom endpoint with user-provided API keys, and they want the models to be fetched dynamically based on each user's API key. Currently, it seems like models are only fetched during Docker setup, but they need it to happen when the user enters their key or logs in/refreshes.


## Investigating LibreChat setup  
- The user wants to configure LibreChat to use their LiteLLM server with custom endpoints and API keys.  
- They need models to be fetched dynamically based on each user's API key, not just during Docker setup.</details></think>

---

<details>
                <summary>Searched codebase "model fetching custom endpoint" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `api/server/services/ModelService.js` | L43-127 |
| `api/server/services/Config/loadConfigModels.js` | L9-108 |
| `api/server/services/Config/loadConfigModels.js` | Lundefined-106 |
| `api/server/services/ModelService.js` | L44-193 |
| `api/server/services/Endpoints/custom/initialize.js` | L18-185 |
| `api/server/services/ModelService.js` | L16-115 |
| `api/server/services/ModelService.js` | L237-311 |
| `api/server/controllers/ModelController.js` | L24-49 |
| `packages/data-provider/src/config.ts` | L283-321 |
| `api/server/controllers/ModelController.js` | L9-47 |
| `packages/data-provider/src/api-endpoints.ts` | L124-130 |
| `api/server/services/ModelService.js` | L128-244 |
| `api/server/services/Config/getEndpointsConfig.js` | Lundefined-103 |
| `packages/api/src/endpoints/custom/config.ts` | Lundefined-55 |
| `api/server/services/start/modelSpecs.js` | L10-74 |

</details>

---

<think><details><summary>Thought Process</summary>Now let me look more specifically at how user-provided API keys are handled and where the model fetching occurs for custom endpoints. I can see from the results that:
</details></think>

---



---

<think><details><summary>Thought Process</summary>Now I can see the key issue! In `loadConfigModels.js` at line 71, there's this condition:


## Examining code condition

- Found a condition in `loadConfigModels.js` at line 71 that checks for `models.fetch`.</details></think>

---

Read file: undefined

---

<think><details><summary>Thought Process</summary>Perfect! Now I can see the exact issue. In `loadConfigModels.js` at line 71, there's this condition:
</details></think>

---

Read file: undefined

---

<think><details><summary>Thought Process</summary>Great! I can see that in the custom endpoint initialization (lines 102-110), there IS logic to fetch models when certain conditions are met:


## Examining Custom Endpoint Logic  
- Found custom endpoint initialization at lines 102-110 includes model fetching logic.</details></think>

---



---

<think><details><summary>Thought Process</summary>Let me find where FetchTokenConfig is defined.</details></think>

---



---

<think><details><summary>Thought Process</summary>Let me search more broadly for FetchTokenConfig.</details></think>

---



---

<think><details><summary>Thought Process</summary>Let me check the FetchTokenConfig enum definition.</details></think>

---

Read file: undefined

---

<think><details><summary>Thought Process</summary>So `FetchTokenConfig` only includes `openrouter`. This means the model fetching logic in the custom endpoint initialization only works for OpenRouter endpoints, not for generic custom endpoints like LiteLLM.
</details></think>

---

Read file: undefined

---

<think><details><summary>Thought Process</summary>Now I understand the full picture! The issue is:


## Understanding the Issue  
- The problem centers on the `loadModels` function and its interaction with `loadConfigModels`.</details></think>

---

<details>
                <summary>Searched codebase "fetch.*model" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `client/src/components/SidePanel/Agents/ModelPanel.tsx` | L16-255 |
| `client/src/hooks/Endpoint/useEndpoints.ts` | L19-187 |
| `client/src/components/Chat/Input/StreamAudio.tsx` | L18-232 |
| `client/src/utils/endpoints.ts` | L133-214 |
| `client/src/utils/buildDefaultConvo.ts` | Lundefined-86 |
| `client/src/components/Chat/Menus/Endpoints/utils.ts` | L13-162 |
| `client/src/hooks/Conversations/useNavigateToConvo.tsx` | Lundefined-94 |
| `client/src/components/Input/ModelSelect/ModelSelect.tsx` | L10-49 |
| `client/src/hooks/Agents/useSelectAgent.ts` | L12-96 |
| `client/src/components/SidePanel/Agents/ModelPanel.tsx` | L18-255 |
| `client/src/components/Chat/Menus/Endpoints/ModelSelectorContext.tsx` | L53-228 |
| `client/src/hooks/Endpoint/useEndpoints.ts` | L19-185 |
| `client/src/hooks/Input/useQueryParams.ts` | L81-457 |
| `client/src/components/SidePanel/Builder/AssistantPanel.tsx` | L34-477 |
| `client/src/components/Chat/Menus/Presets/EditPresetDialog.tsx` | L23-227 |

</details>

---

<think><details><summary>Thought Process</summary>Now I need to search for GitHub issues or documentation that might address this specific issue. Let me also check if there are any existing solutions or workarounds mentioned in the codebase or documentation.</details></think>

---



---

<think><details><summary>Thought Process</summary>Let me search for any existing issues or documentation about dynamic model fetching with user-provided keys. Let me also check the documentation directory.</details></think>

---

<details>
            <summary>Listed directory undefined • **0** results</summary>
        
No results found
</details>

---

<think><details><summary>Thought Process</summary>Let me check the README and documentation files to see if there's any information about dynamic model fetching.</details></think>

---

Read file: undefined

---

<think><details><summary>Thought Process</summary>Let me search for specific GitHub issues or discussions about dynamic model fetching. I'll also look for any existing solutions or workarounds in the codebase.</details></think>

---

```bash
curl -s "https://api.github.com/search/issues?q=repo:danny-avila/LibreChat+model+fetch+user+provided&sort=created&order=desc" | head -50
```

```
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo
PS C:\Users\JoshS\Documents\GitHub\LibreChat> curl -s "https://api.github.com/search/issues?q=repo:da
head : The term 'head' is not recognized as the name of a cmdlet, function, script file, or
operable program. Check the spelling of the name, or if a path was included, verify that the path    
is correct and try again.
At line:1 char:129
+ ... breChat+model+fetch+user+provided&sort=created&order=desc" | head -50
+                                                                  ~~~~
    + CategoryInfo          : ObjectNotFound: (head:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

PS C:\Users\JoshS\Documents\GitHub\LibreChat>
```

---

<think><details><summary>Thought Process</summary>Let me try a simpler approach and use PowerShell's built-in commands. Let me also search for any existing solutions in the codebase.</details></think>

---

```bash
Invoke-WebRequest -Uri "https://api.github.com/search/issues?q=repo:danny-avila/LibreChat+model+fetch+user+provided&sort=created&order=desc" -UseBasicParsing | Select-Object -ExpandProperty Content
```

```
PS C:\Users\JoshS\Documents\GitHub\LibreChat> Invoke-WebRequest -Uri "https://api.github.
Oops, something went wrong.  Please report this bug with the details below.
Report on GitHub: https://github.com/PowerShell/PSReadLine/issues/new
### Environment
PSReadLine: 2.0.0
PowerShell: 5.1.26100.5770
OS: Microsoft Windows 10.0.26120
Last 189 Keys
```
 c u r l Spacebar - s Spacebar " h t t p s : / / a p i . g i t h u b . c o m / s e a r c h / i s s u 
e s ? q = r e p o : d a n n y - a v i l a / L i b r e C h a t + m o d e l + f e t c h + u s e r + p r
 o v i d e d & s o r t = c r e a t e d & o r d e r = d e s c " Spacebar | Spacebar h e a d Spacebar -
 5 0 Enter
 Ctrl+c I n v o k e - W e b R e q u e s t Spacebar - U r i Spacebar " h t t p s : / / a p i . g i t h
 u b . c o m / s e a r
```

### Exception
```
System.ArgumentOutOfRangeException: The value must be greater than or equal to zero and less than the
 console's buffer size in that dimension.
Parameter name: top
Actual value was 10.
   at System.Console.SetCursorPosition(Int32 left, Int32 top)
   at Microsoft.PowerShell.PSConsoleReadLine.ReallyRender(RenderData renderData, String defaultColor)
   at Microsoft.PowerShell.PSConsoleReadLine.ForceRender()
   at Microsoft.PowerShell.PSConsoleReadLine.Insert(Char c)
   at Microsoft.PowerShell.PSConsoleReadLine.SelfInsert(Nullable`1 key, Object arg)
   at Microsoft.PowerShell.PSConsoleReadLine.ProcessOneKey(PSKeyInfo key, Dictionary`2 dispatchTable,
 Boolean ignoreIfNoAction, Object arg)
   at Microsoft.PowerShell.PSConsoleReadLine.InputLoop()
   at Microsoft.PowerShell.PSConsoleReadLine.ReadLine(Runspace runspace, EngineIntrinsics engineIntri
nsics, CancellationToken cancellationToken)
```

PS C:\Users\JoshS\Documents\GitHub\LibreChat> Invoke-WebRequest -Uri "https://api.github.com/search/i
ssues?q=repo:danny-avila/LibreChat+model+fetch+user+provided&sort=created&order=desc" -UseBasicParsin
                                                                                                     
 Reading web response                                                                                
    Reading response stream... (Number of bytes read: 183098)
```

---



---

